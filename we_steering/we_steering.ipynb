{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b0d5d8350f9b4b",
   "metadata": {},
   "source": [
    "# preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941233b",
   "metadata": {},
   "source": [
    "## loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bcc3f5d62070ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/extended_esc_13b.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce2ab7",
   "metadata": {},
   "source": [
    "## converting to chat format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03387528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of conversations:  9354\n",
      "no of sampels:  41822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'hello im looking for someone to talk to  im fine how are you'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"I'm doing ok I'm glad you are good. Is it snowing by you? Merry Christmas!\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'thats great and no its not snowing its very cold thow\\n merry christmas to you also'},\n",
       "  {'role': 'assistant', 'content': 'How can I help you today?'},\n",
       "  {'role': 'user',\n",
       "   'content': 'im having some issues with friends not actually being friends'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"I hear you are having trouble figuring out which friends are really your friends and which ones aren't. Is that about right?\"},\n",
       "  {'role': 'user', 'content': 'yes'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'I understand that... Did something happen that makes you feel like that?'},\n",
       "  {'role': 'user',\n",
       "   'content': 'yes their is no communication or interaction between me and them nobody answers phone calls txt messages etc'},\n",
       "  {'role': 'assistant', 'content': 'Is this a significant other?'},\n",
       "  {'role': 'user', 'content': 'no friends'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"it sounds like you're feeling really frustrated and isolated with your friend situation. instead of thinking of it as a complete loss, could we try to see it as an opportunity to focus on other relationships or activities that do bring you joy and fulfillment? maybe there are other people or hobbies that you've been neglecting that could fill this gap. additionally, it's important to remember that it's okay to have different types of relationships and not everyone will be a close friend. let's try to focus on the positive aspects of your life and what you can control in this situation.\"}],\n",
       " 'strategy': 'Reframe Negative Thoughts'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "processed_convs = []\n",
    "\n",
    "print(\"no of conversations: \", len(data))\n",
    "\n",
    "for ex in data:\n",
    "    messages = []\n",
    "    speakers = ['user' if s == 'seeker' else 'assistant' for s in ex['speakers']]\n",
    "    turns = [t.strip() for t in ex['dialog']]\n",
    "    \n",
    "    for s, t in zip(speakers, turns):\n",
    "        messages.append({'role': s, 'content': t})\n",
    "        \n",
    "    for label, resp in ex['responses'].items():\n",
    "        cur_msgs = copy(messages)\n",
    "        cur_msgs.append({'role': 'assistant', 'content': resp})\n",
    "        \n",
    "        processed_convs.append({'messages': cur_msgs, 'strategy': label})\n",
    "    \n",
    "    \n",
    "print(\"no of sampels: \", len(processed_convs))\n",
    "processed_convs[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7439b15",
   "metadata": {},
   "source": [
    "## taking a sample of data for PoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0706a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.shuffle(processed_convs)\n",
    "\n",
    "sample = processed_convs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b471d4",
   "metadata": {},
   "source": [
    "# probing the token embeddings of the responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22453130",
   "metadata": {},
   "source": [
    "## loading a dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2af4cd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base prompt len: 339\n",
      "full prompt len: 438\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaModel, LlamaConfig\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "config = LlamaConfig(num_hidden_layers=1)\n",
    "model = LlamaModel(config=config)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def get_assistant_response_embeddings(conv: List[Dict[str, str]]) -> np.ndarray:\n",
    "    prompt_tokens = tokenizer.apply_chat_template(conv[:-1], tokenize=True)\n",
    "    prompt_len = len(prompt_tokens)\n",
    "\n",
    "    full_prompt = tokenizer.apply_chat_template(conv, tokenize=True)\n",
    "    print(\"base prompt len:\", prompt_len)\n",
    "    print(\"full prompt len:\", len(full_prompt))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=torch.tensor([full_prompt]).to(device))\n",
    "    \n",
    "    out_emb = outputs.last_hidden_state.cpu().numpy()[0]\n",
    "    return out_emb[prompt_len:-1, :]\n",
    "\n",
    "out = get_assistant_response_embeddings(sample[0]['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b94b67ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 4096)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17925915",
   "metadata": {},
   "source": [
    "# train projection weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55847110",
   "metadata": {},
   "source": [
    "## load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f82633f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/sample_embeddings.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c0c00d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Provide Different Perspectives',\n",
       "  'Provide Different Perspectives',\n",
       "  'Provide Different Perspectives',\n",
       "  'Provide Different Perspectives',\n",
       "  'Provide Different Perspectives',\n",
       "  'Provide Different Perspectives',\n",
       "  'Provide Different Perspectives',\n",
       "  'Provide Different Perspectives',\n",
       "  'Provide Different Perspectives',\n",
       "  'Provide Different Perspectives'],\n",
       " (114929, 4096))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][:10], data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "237ce769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "f1 score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navid/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=6.72043e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_numeric = label_encoder.fit_transform(data[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[0], y_numeric, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = RidgeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f'f1 score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1375b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
